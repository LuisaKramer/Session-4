---
title: "Hausaufgabe Luisa Kramer 4. Session"
output:
  html_document:
    df_print: paged
---

# Libraries und Daten
```{r}
library(tidyverse)
library(e1071)
library(caret)
library(pROC)
```

```{r}
titanic <- read_delim("titanic.csv", ";", 
    escape_double = FALSE, trim_ws = TRUE)
```

# Class Imbalance Check

```{r}
titanic %>%
  group_by(survived) %>%
  summarize(n = n())
```

# Auswertung, wie viele Kinder unter 14 Jahren an Bord waren und wie viele davon überlebt haben
```{r}
titanic %>%
  filter(age < 15) %>%
  summarise(n = n())
```
```{r}
titanic %>%
  filter(age < 15, survived == 1) %>%
  summarise(n = n())
```
# Auswertung, wie viele Kinder von der jeweiligen Klasse überlebent haben - gestorben sind
```{r}
titanic %>%
  filter(age < 15) %>%
  group_by(survived, sex, pclass) %>%
  summarise(n = n())
```

# Anzahl der Passagiere in den jeweiligen Klassen
```{r}
titanic %>%
  group_by(pclass) %>%
  summarise(n = n())
```


# Auswertung, wie viele Männer und Frauen gestorben sind, sowie überlebt haben
```{r}
titanic %>%
  group_by(survived,sex) %>%
  summarise(n = n())
```

# Auswerten der verschiedenen Klassen, nach Geschlecht und ob diese überlebt haben oder gestorben sind
```{r}
titanic %>%
  group_by(pclass, sex, survived) %>%
  summarise(n = n())
```

# Anzeigen der Anzahl der Passagiere aus den verschiedenen Klassen, die in den 3 Einstiegshäfen zugestiegen sind
```{r}
titanic %>%
  group_by(embarked,pclass) %>%
  summarise(n = n())
```

# Mit mehr als zwei Features

# Urpsprünglich wollte ich die Klasse "Cabin" nehmen und den Kabinnennummern die Decks zuweisen, um so herauszufinden, ob z.B. Passagiere von Deck G häufiger gestorben sind als von Deck A. Die Titanic hatte Deck A,B,C,D,E,F,G - nach meiner Recherche musste ich aber feststellen, dass Kabinen aller 3 Klassen gleichmäßig auf alle Decks verteilt waren, somit macht eine Abfrage mit den Kabinen keinen Sinn, leider fehlt die Kabinennummer auch sehr häufig in den Daten.

# Einbauen der Abfrage in Bezug auf den Einstiegshafen (S=Southhampton, C=Cherbourgh, Q=Queenstown)

```{r}
(features.titanic <- titanic %>%
  select(survived,pclass,sex,age,embarked))
```

```{r}
features.titanic <- features.titanic %>%
  mutate(age = as.numeric(str_replace(age,",",".")))
```

```{r}
features.titanic <- na.omit(features.titanic)
```

```{r}
features.titanic <- features.titanic %>%
  mutate(sex = ifelse(sex == "female", 1, 0))
```

```{r}
set.seed(136)
inTrain <- createDataPartition(
  y = features.titanic$survived,
  p = .8,
  list = FALSE)
training <- features.titanic[ inTrain,]
testing  <- features.titanic[-inTrain,]
```

```{r}
model <- svm(survived ~ ., data = training)
summary(model)
pred <- predict(model, testing[,-1], probability = FALSE)
```

```{r}
(test.results <- cbind(pred, testing))
```


```{r}
library(pROC)
pROC_obj <- roc(test.results$survived, test.results$pred,
            smoothed = TRUE,
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
```

# Naive Bayes

```{r}
my_training <- training %>%
  mutate(survived = as.factor(survived))%>%
  mutate(sex = as.factor(sex))%>%
  mutate(pclass = as.factor(pclass)) %>%
  mutate(age = as.factor(age))  
model <- naiveBayes(survived ~ ., data = my_training)
model
```

```{r}
my_testing <- testing %>%
  mutate(sex = as.factor(sex)) %>%
  mutate(pclass = as.factor(pclass))%>%
  mutate(age = as.factor(ifelse(age < 15, "child", "adult")))
pred <- predict(model, my_testing)
table(pred, my_testing$survived)
```


```{r}
(test.results <- cbind(pred, my_testing))
```

```{r}
test.results <- test.results %>%
  mutate(pred = as.numeric(pred))
pROC_obj <- roc(as.numeric(as.character(test.results$survived)), test.results$pred,
            smoothed = TRUE,
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
```
# Decision Tree

```{r}
library(rpart)
library(rpart.plot)
tree<- rpart(survived~., data = training, method = 'class')
rpart.plot(tree)
```
```{r}
dt_results <- predict(tree, testing[,-1], type = 'prob')
head(model.results.dt <- cbind(testing,dt_results),500)
```
```{r}
test.results2 <- test.results %>%
  mutate(pred = ifelse(pred>=0.5,1,0))
table(test.results2$pred, testing$survived)
```


```{r}
pROC_obj <- roc(model.results.dt$survived,model.results.dt$`1`,
            smoothed = TRUE,
            # arguments for ci
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            # arguments for plot
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
```
# Unterschiede in der Performance der Algorithmen + Versuch, Erklärungen zu finden:

# Die Leistung der Algorithmen ist immer abhängig von den verwendeten Daten. Man kann nicht sagen, welcher Algorithmus genauer ist. Die Qualität der Daten spielt eine große Rolle, spezielle Fehlerfälle müssen erst behandelt werden. Ich könnte mir vorstellen, dass jeder Algorithmus ein spezielles Eingabeformat hat und die Daten entsprechend aufbereitet werden müssen, damit die Algorithmen optimierter laufen. Unterschiede in der Leistung der Algorithmen können sicher auch durch unterschiedliche Verwendung von Hard- und Software passieren. Decision Trees sind deutlich übersichtlicher und leicht zu verstehen. Ich habe im Code aber festgestellt, dass weniger Ergebnisse im Decision Tree angezeigt werden, je mehr Klassen man hinzunimmt – Decision Trees eignen sich also nur bis zu einer gewissen Komplexität. Online habe ich gefunden, dass der Naive Bayes-Klassifikator im Vergleich mit anderen Klassifikationsmethoden theoretisch der genaueste Klassifikator wäre. Die Algorithmen unterscheiden sich auch in der Zeitdauer, die das Programm benötigt, um die Aufgabe zu lösen. 
